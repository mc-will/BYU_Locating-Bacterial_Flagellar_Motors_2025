{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1b9b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 15:59:51.365035: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from tensorflow.keras import Sequential, Input, layers\n",
    "from tensorflow_addons.metrics import FBetaScore\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from src.utils.data import get_csv_from_bq,select_tomo_ids\n",
    "\n",
    "#from utils.model_plot import plot_history2\n",
    "from src.utils.model_plot import plot_history_regression\n",
    "from src.ml_logic.preprocess import batches_images_ram,selection_images_labels,read_img_jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from src.utils.data import get_csv_from_bq,select_tomo_ids\n",
    "\n",
    "def selection_images_labels(df, num_slices=[300,500,800], num_motors=[0,1]):\n",
    "\n",
    "   # Step 1: Filter tomos\n",
    "    tomo_ids = 'tomo_0a8f05', 'tomo_0a180f', 'tomo_0c3a99', 'tomo_0c3d78'\n",
    "    #select_tomo_ids(df, number_of_slices=num_slices, number_of_motors=num_motors)\n",
    "    df_select = df[df['tomo_id'].isin(tomo_ids)].copy()\n",
    "\n",
    "    # Step 2: Set up labels\n",
    "   # df_select['Number_of_motors'] = df_select.apply(lambda row: (row['Motor_axis_2'], row['Motor_axis_1']), axis=1)\n",
    "\n",
    "    # Step 3: Load all images\n",
    "    dir_mean_image = '../data/pictures_process/train_process/'\n",
    "    all_images = glob.glob(os.path.join(dir_mean_image, '**', '*.jpg'), recursive=True)\n",
    "\n",
    "    print(f\"Found {len(all_images)} images in {dir_mean_image}\")\n",
    "\n",
    "    # Step 4: Match images using substring matching\n",
    "    filtered_image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df_select.iterrows():\n",
    "        tomo_id = row['tomo_id']\n",
    "        print(tomo_id)\n",
    "        matched = [print(p) for p in all_images if tomo_id in os.path.basename(p)]\n",
    "\n",
    "        if matched:\n",
    "            filtered_image_paths.append(matched[0])  # If multiple, take the first\n",
    "            labels.append(row['Number_of_motors'])\n",
    "        else:\n",
    "            print(f\"⚠️ No image found for tomo_id: {tomo_id}\")\n",
    "\n",
    "    print(f\"Matched {len(filtered_image_paths)} image-label pairs\")\n",
    "\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    return filtered_image_paths, labels\n",
    "\n",
    "\n",
    "# Define image reading function\n",
    "def read_img_jpg(path, label):\n",
    "\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=1)\n",
    "    img = tf.cast(img, tf.float32) / 255.0  # normalize to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "\n",
    "\n",
    "def batches_images_ram(\n",
    "    read_img_jpg,\n",
    "    filtered_image_paths,\n",
    "    labels,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    split=False,\n",
    "    val_fraction=0.2,\n",
    "    test_fraction=0.2,\n",
    "    seed=42):\n",
    "\n",
    "\n",
    "    dataset_size = len(filtered_image_paths)\n",
    "    # Combine and optionally shuffle the data as a list of tuples\n",
    "    data = list(zip(filtered_image_paths, labels))\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rng.shuffle(data)\n",
    "\n",
    "    # Unzip the shuffled data back\n",
    "    filtered_image_paths, labels = zip(*data)\n",
    "\n",
    "    # Convert back to lists or arrays\n",
    "    filtered_image_paths = list(filtered_image_paths)\n",
    "    labels = list(labels)\n",
    "\n",
    "    if split:\n",
    "        # Compute sizes\n",
    "        val_size = int(val_fraction * dataset_size)\n",
    "        test_size = int(test_fraction * dataset_size)\n",
    "        train_size = dataset_size - val_size - test_size\n",
    "\n",
    "        # Split into slices\n",
    "        test_paths = filtered_image_paths[:test_size]\n",
    "        test_labels = labels[:test_size]\n",
    "\n",
    "        val_paths = filtered_image_paths[test_size:test_size + val_size]\n",
    "        val_labels = labels[test_size:test_size + val_size]\n",
    "\n",
    "        train_paths = filtered_image_paths[test_size + val_size:]\n",
    "        train_labels = labels[test_size + val_size:]\n",
    "\n",
    "        # Create tf.data.Dataset for each\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels)).map(read_img_jpg).batch(batch_size)\n",
    "        val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels)).map(read_img_jpg).batch(batch_size)\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels)).map(read_img_jpg).batch(batch_size)\n",
    "\n",
    "        return train_ds, val_ds, test_ds, test_paths, test_labels\n",
    "\n",
    "    else:\n",
    "        # Single dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filtered_image_paths, labels))\n",
    "        dataset = dataset.map(read_img_jpg).batch(batch_size)\n",
    "        return dataset, filtered_image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e529680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images in ../data/pictures_process/train_process/\n",
      "tomo_0a180f\n",
      "⚠️ No image found for tomo_id: tomo_0a180f\n",
      "tomo_0c3d78\n",
      "⚠️ No image found for tomo_id: tomo_0c3d78\n",
      "tomo_0a8f05\n",
      "⚠️ No image found for tomo_id: tomo_0a8f05\n",
      "tomo_0c3a99\n",
      "⚠️ No image found for tomo_id: tomo_0c3a99\n",
      "Matched 0 image-label pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], array([], dtype=float32))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_images_labels(df, num_slices=[300,500,800], num_motors=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed6c0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from src.utils.image_padding import padd_picture\n",
    "\n",
    "def pad_stack_z_with_2d_padding(\n",
    "    folder_path,\n",
    "    padded_folder_path,\n",
    "    xy_size,\n",
    "    target_depth=800,\n",
    "    pad_value=255\n",
    "):\n",
    "    \"\"\"\n",
    "    Pads all slices in a folder to (xy_size, xy_size) and pads stack to target_depth.\n",
    "    Saves padded 2D images in padded_folder_path.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray: padded stack of shape (target_depth, xy_size, xy_size, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    def numeric_sort_key(filename):\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return int(numbers[0]) if numbers else -1\n",
    "\n",
    "    # Get sorted image paths with numeric sorting\n",
    "    image_files = sorted(\n",
    "        [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))],\n",
    "        key=numeric_sort_key\n",
    "    )\n",
    "\n",
    "    padded_images = []\n",
    "    for file in image_files:\n",
    "        source_path = os.path.join(folder_path, file)\n",
    "        dest_path = os.path.join(padded_folder_path, file)\n",
    "\n",
    "        # Pad 2D image to xy_size x xy_size and save\n",
    "        padd_picture(source_path, dest_path, xy_size)\n",
    "\n",
    "        # Load padded image as numpy array\n",
    "        img = Image.open(dest_path).convert('RGB')\n",
    "        padded_images.append(np.array(img))\n",
    "\n",
    "    stack = np.stack(padded_images, axis=0)  # (Z, xy_size, xy_size, 3)\n",
    "    current_depth = stack.shape[0]\n",
    "    print(current_depth)\n",
    "    if current_depth > target_depth:\n",
    "        raise ValueError(f\"Stack depth {current_depth} exceeds target {target_depth}\")\n",
    "\n",
    "    pad_slices = target_depth - current_depth\n",
    "    print(pad_slices)\n",
    "    if pad_slices > 0:\n",
    "        # Save white padding slices as images on disk\n",
    "        for i in range(pad_slices):\n",
    "            pad_slice_index = current_depth + i + 1\n",
    "            pad_filename = f\"slice_{pad_slice_index}.jpg\"  # or adapt naming\n",
    "            pad_filepath = os.path.join(padded_folder_path, pad_filename)\n",
    "\n",
    "            white_img = Image.new('RGB', (xy_size, xy_size), (pad_value, pad_value, pad_value))\n",
    "            white_img.save(pad_filepath)\n",
    "\n",
    "            # Append white slice to the stack list\n",
    "            padded_images.append(np.array(white_img))\n",
    "\n",
    "        # Recreate stack with padding slices included\n",
    "        stack = np.stack(padded_images, axis=0)\n",
    "\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34f78a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>row_id</th>\n",
       "      <th>tomo_id</th>\n",
       "      <th>Motor_axis_0</th>\n",
       "      <th>Motor_axis_1</th>\n",
       "      <th>Motor_axis_2</th>\n",
       "      <th>Array_shape_axis_0</th>\n",
       "      <th>Array_shape_axis_1</th>\n",
       "      <th>Array_shape_axis_2</th>\n",
       "      <th>Voxel_spacing</th>\n",
       "      <th>Number_of_motors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>tomo_0c3d78</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>928</td>\n",
       "      <td>960</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  row_id      tomo_id  Motor_axis_0  Motor_axis_1  Motor_axis_2  \\\n",
       "50          50      35  tomo_0c3d78          -1.0          -1.0          -1.0   \n",
       "\n",
       "    Array_shape_axis_0  Array_shape_axis_1  Array_shape_axis_2  Voxel_spacing  \\\n",
       "50                 800                 928                 960           13.1   \n",
       "\n",
       "    Number_of_motors  \n",
       "50                 0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tomo_id']=='tomo_0a8f05']\n",
    "df[df['tomo_id']=='tomo_0a180f']\n",
    "df[df['tomo_id']=='tomo_0c3a99']\n",
    "df[df['tomo_id']=='tomo_0c3d78']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c430d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "0\n",
      "(800, 960, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "padded_stack = pad_stack_z_with_2d_padding(\n",
    "    folder_path='../data/pictures_raw/train/tomo_0c3d78',\n",
    "    padded_folder_path='../data/pictures_process/train_process/tomo_0c3d78_padded',\n",
    "    xy_size=960,\n",
    "    target_depth=800,\n",
    "    pad_value=255  # white background\n",
    ")\n",
    "\n",
    "print(padded_stack.shape)  # (800, 960, 960, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef49c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_csv= '../data/csv_raw/train_labels.csv'\n",
    "path_image= '../data/pictures_process/train_process'\n",
    "\n",
    "df = pd.read_csv(path_train_csv).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4286d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>row_id</th>\n",
       "      <th>tomo_id</th>\n",
       "      <th>Motor_axis_0</th>\n",
       "      <th>Motor_axis_1</th>\n",
       "      <th>Motor_axis_2</th>\n",
       "      <th>Array_shape_axis_0</th>\n",
       "      <th>Array_shape_axis_1</th>\n",
       "      <th>Array_shape_axis_2</th>\n",
       "      <th>Voxel_spacing</th>\n",
       "      <th>Number_of_motors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>tomo_049310</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>tomo_098751</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>tomo_136c8d</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>tomo_146de2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>tomo_1dc5f9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>tomo_28f9c1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>tomo_39b15b</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>181</td>\n",
       "      <td>tomo_3b8291</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>193</td>\n",
       "      <td>tomo_40b215</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>219</td>\n",
       "      <td>tomo_4baff0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  row_id      tomo_id  Motor_axis_0  Motor_axis_1  Motor_axis_2  \\\n",
       "0           0      16  tomo_049310          -1.0          -1.0          -1.0   \n",
       "1           1      30  tomo_098751          -1.0          -1.0          -1.0   \n",
       "2           2      54  tomo_136c8d          -1.0          -1.0          -1.0   \n",
       "3           3      59  tomo_146de2          -1.0          -1.0          -1.0   \n",
       "4           4      84  tomo_1dc5f9          -1.0          -1.0          -1.0   \n",
       "5           5     121  tomo_28f9c1          -1.0          -1.0          -1.0   \n",
       "6           6     173  tomo_39b15b          -1.0          -1.0          -1.0   \n",
       "7           7     181  tomo_3b8291          -1.0          -1.0          -1.0   \n",
       "8           8     193  tomo_40b215          -1.0          -1.0          -1.0   \n",
       "9           9     219  tomo_4baff0          -1.0          -1.0          -1.0   \n",
       "\n",
       "   Array_shape_axis_0  Array_shape_axis_1  Array_shape_axis_2  Voxel_spacing  \\\n",
       "0                 500                 924                 956           19.7   \n",
       "1                 500                 924                 956           16.1   \n",
       "2                 500                 924                 956           19.7   \n",
       "3                 500                 924                 956           16.1   \n",
       "4                 500                 924                 956           19.7   \n",
       "5                 500                 924                 956           16.1   \n",
       "6                 500                 924                 956           16.1   \n",
       "7                 500                 924                 956           19.7   \n",
       "8                 500                 924                 956           16.1   \n",
       "9                 500                 924                 956           16.1   \n",
       "\n",
       "   Number_of_motors  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/csv_raw/train_labels.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e3021b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>row_id</th>\n",
       "      <th>tomo_id</th>\n",
       "      <th>Motor_axis_0</th>\n",
       "      <th>Motor_axis_1</th>\n",
       "      <th>Motor_axis_2</th>\n",
       "      <th>Array_shape_axis_0</th>\n",
       "      <th>Array_shape_axis_1</th>\n",
       "      <th>Array_shape_axis_2</th>\n",
       "      <th>Voxel_spacing</th>\n",
       "      <th>Number_of_motors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>tomo_0a180f</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>928</td>\n",
       "      <td>960</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>tomo_0c3d78</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>928</td>\n",
       "      <td>960</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>32</td>\n",
       "      <td>tomo_0a8f05</td>\n",
       "      <td>52.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>300</td>\n",
       "      <td>928</td>\n",
       "      <td>928</td>\n",
       "      <td>13.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>343</td>\n",
       "      <td>34</td>\n",
       "      <td>tomo_0c3a99</td>\n",
       "      <td>125.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>300</td>\n",
       "      <td>959</td>\n",
       "      <td>928</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  row_id      tomo_id  Motor_axis_0  Motor_axis_1  \\\n",
       "49           49      31  tomo_0a180f          -1.0          -1.0   \n",
       "50           50      35  tomo_0c3d78          -1.0          -1.0   \n",
       "292         292      32  tomo_0a8f05          52.0         587.0   \n",
       "343         343      34  tomo_0c3a99         125.0         645.0   \n",
       "\n",
       "     Motor_axis_2  Array_shape_axis_0  Array_shape_axis_1  Array_shape_axis_2  \\\n",
       "49           -1.0                 800                 928                 960   \n",
       "50           -1.0                 800                 928                 960   \n",
       "292         575.0                 300                 928                 928   \n",
       "343         227.0                 300                 959                 928   \n",
       "\n",
       "     Voxel_spacing  Number_of_motors  \n",
       "49            13.1                 0  \n",
       "50            13.1                 0  \n",
       "292           13.1                 1  \n",
       "343           15.6                 1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select = df[df['tomo_id'].isin(['tomo_0a8f05', 'tomo_0a180f', 'tomo_0c3a99', 'tomo_0c3d78'])].copy()\n",
    "df_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_model3D():\n",
    "\n",
    "    model = Sequential()\n",
    "     ### First Convolution & MaxPooling\n",
    "    model.add(Input(shape=(X.shape)))\n",
    "    model.add(layers.Conv3D(32, (3,3,3), activation = 'relu',padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D(pool_size=(3, 3, 3)))\n",
    "    model.add(layers.Conv3D(64, (4,4,4), activation = 'relu',padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D(pool_size=(3, 3, 3)))\n",
    "\n",
    "    ## Flattening\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
    "    model.add(layers.Dense(10,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dropout(0.3))  # Optional\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb46883",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv3d\" is incompatible with the layer: expected min_ndim=5, found ndim=4. Full shape received: (None, 960, 960, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43minitiate_model3D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36minitiate_model3D\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[38;5;66;03m### First Convolution & MaxPooling\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m960\u001b[39m, \u001b[38;5;241m960\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv3D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mBatchNormalization())\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mMaxPool2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/keras/engine/input_spec.py:250\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv3d\" is incompatible with the layer: expected min_ndim=5, found ndim=4. Full shape received: (None, 960, 960, 1)"
     ]
    }
   ],
   "source": [
    "model = initiate_model3D()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae977ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def euclidean_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.norm(y_pred - y_true, axis=1))\n",
    "def compile_model3D_regress(model):\n",
    "    ### Model compilation\n",
    "    #model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['FBetaScore',Recall(),'precision','accuracy'], run_eagerly=True)\n",
    "\n",
    "    model.compile(loss= 'binary_crossentropy',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics=['accuracy',\n",
    "                           FBetaScore(num_classes=1,\n",
    "                                      average='micro',\n",
    "                                      beta=2.0),\n",
    "                           Recall(),\n",
    "                        #    'precision',\n",
    "                           ],)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2e18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_logic.interface import train\n",
    "model = initiate_model3D()\n",
    "model = compile_model3D_regress(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4e34d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train(model,\n\u001b[0;32m----> 2\u001b[0m         \u001b[43mtrain_ds\u001b[49m,\n\u001b[1;32m      3\u001b[0m         val_ds,\n\u001b[1;32m      4\u001b[0m         model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassif3D\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m         preprocess_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_tomo_0a8f05_0a180f_0c3a99\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassif3D_0a8f05_0a180f_0c3a99\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      8\u001b[0m         patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      9\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "def model_train (model, X_train_processed, y_train, batch_size=16 ,epochs=100):\n",
    "    verbose=1\n",
    "    validation_split=0.1\n",
    "    es = EarlyStopping(patience=3,\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train_processed,\n",
    "                        y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        # validation_split=validation_split,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[es],\n",
    "                        verbose=verbose)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6da765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flagelleux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
