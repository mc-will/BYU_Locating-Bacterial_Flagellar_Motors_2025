{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937f2b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:54:58.753605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-04 14:54:58.974420: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-06-04 14:54:58.974507: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-06-04 14:54:59.039033: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 14:54:59.958245: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-04 14:54:59.958380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-06-04 14:54:59.958392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.utils.data import select_tomo_ids\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "from keras import Sequential, Input, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff19f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice_file_path(tomogram_id, z):\n",
    "    '''\n",
    "    accès au chemin d'une slice en fonction de l'identifiant du tomogramme et de l'indice de la slice\n",
    "    Parameters:\n",
    "        tomogram_id (str): l'identifiant du tomogramme\n",
    "        z (int): l'indice de la slice\n",
    "    Returns:\n",
    "        str: le chemin de l'image\n",
    "    '''\n",
    "    tomogrammes_train_dir = './data/pictures_raw/train/'\n",
    "    file_name = f'slice_{str(int(z)).zfill(4)}.jpg'\n",
    "    #print(f'get_slice_file_path: {tomogram_id} {z} {file_name}')\n",
    "    image_path = os.path.join(tomogrammes_train_dir, tomogram_id, file_name)\n",
    "    return image_path\n",
    "\n",
    "def get_motor_coordinates(df, tomogram_id):\n",
    "    '''\n",
    "    Récupération des coordonnées du moteur dans le tomogramme\n",
    "    Parameters:\n",
    "        df (pd.Dataframe): le dataframe des données\n",
    "        tomogram_id (str): l'identifiant du tomogramme\n",
    "    Returns:\n",
    "        tuple: les coordonnées du moteur\n",
    "    '''\n",
    "    df_tomogram = df[df['tomo_id'] == tomogram_id]\n",
    "    x = df_tomogram['Motor_axis_2'].values[0]\n",
    "    y = df_tomogram['Motor_axis_1'].values[0]\n",
    "    z = df_tomogram['Motor_axis_0'].values[0]\n",
    "\n",
    "\n",
    "    ############# MODIFIE !!!!!! #################\n",
    "    numb_motors = df_tomogram['Number_of_motors'].values[0]\n",
    "    #print(f'get_motor_coordinates: {tomogram_id} {x} {y} {z}')\n",
    "    return x, y, z, numb_motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b51922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Number_of_motors</th>\n",
       "      <th>picture_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>762.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_05df8a/slice_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_0a8f05/slice_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>636.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_0da370/slice_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_101279/slice_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>658.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_13484c/slice_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>387.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_f78e91/slice_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>115.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_f871ad/slice_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>491.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_fc3c39/slice_01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>313.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_fc5ae4/slice_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>627.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>./data/pictures_raw/train/tomo_fd5b38/slice_01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x      y  Number_of_motors  \\\n",
       "0    762.0  257.0                 1   \n",
       "1    575.0  587.0                 1   \n",
       "2    636.0  356.0                 1   \n",
       "3    585.0  295.0                 1   \n",
       "4    658.0  768.0                 1   \n",
       "..     ...    ...               ...   \n",
       "300  387.0  469.0                 1   \n",
       "301  115.0  642.0                 1   \n",
       "302  491.0  537.0                 1   \n",
       "303  313.0  513.0                 1   \n",
       "304  627.0  520.0                 1   \n",
       "\n",
       "                                        picture_source  \n",
       "0    ./data/pictures_raw/train/tomo_05df8a/slice_01...  \n",
       "1    ./data/pictures_raw/train/tomo_0a8f05/slice_00...  \n",
       "2    ./data/pictures_raw/train/tomo_0da370/slice_00...  \n",
       "3    ./data/pictures_raw/train/tomo_101279/slice_01...  \n",
       "4    ./data/pictures_raw/train/tomo_13484c/slice_01...  \n",
       "..                                                 ...  \n",
       "300  ./data/pictures_raw/train/tomo_f78e91/slice_00...  \n",
       "301  ./data/pictures_raw/train/tomo_f871ad/slice_01...  \n",
       "302  ./data/pictures_raw/train/tomo_fc3c39/slice_01...  \n",
       "303  ./data/pictures_raw/train/tomo_fc5ae4/slice_00...  \n",
       "304  ./data/pictures_raw/train/tomo_fd5b38/slice_01...  \n",
       "\n",
       "[305 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/csv_raw/train_labels.csv')\n",
    "\n",
    "ids_list = select_tomo_ids(df, number_of_motors=[1])\n",
    "\n",
    "rows = []\n",
    "\n",
    "for id in ids_list:\n",
    "    x, y, z, numb_motors = get_motor_coordinates(df, id)\n",
    "    image_path = get_slice_file_path(id, z)\n",
    "    rows.append([x, y, numb_motors, image_path])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"x\", \"y\", \"Number_of_motors\", \"picture_source\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc9b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df.Number_of_motors\n",
    "\n",
    "# X = []\n",
    "\n",
    "# for source in df.picture_source:\n",
    "#     best_slice_path = os.path.join(f'.{source}')\n",
    "\n",
    "#     img = load_img(best_slice_path, color_mode='grayscale')\n",
    "#     img_array = img_to_array(img) / 255\n",
    "\n",
    "#     # append to the slice list\n",
    "#     X.append(img_array)\n",
    "\n",
    "# X = np.array(X)\n",
    "\n",
    "\n",
    "X = []\n",
    "\n",
    "for source in df.picture_source:\n",
    "    best_slice_path = os.path.join(f'.{source}')\n",
    "\n",
    "    img = load_img(best_slice_path, color_mode='grayscale', target_size=(128, 128))  # ou autre taille\n",
    "    img_array = img_to_array(img) / 255.0  # shape: (128, 128, 1)\n",
    "\n",
    "    X.append(img_array)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0059fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 128, 128, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1ab33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a49ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b29af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfbc672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1b4514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:55:04.330673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-06-04 14:55:04.330746: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-06-04 14:55:04.330786: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ADMINIS-I3M0BV4): /proc/driver/nvidia/version does not exist\n",
      "2025-06-04 14:55:04.331166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def init_model_cnnlog(X):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape= X.shape[1:]))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3),\n",
    "                            padding='same',\n",
    "                            activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(32, (3, 3),\n",
    "                            padding='same',\n",
    "                            activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3),\n",
    "                            padding='same',\n",
    "                            activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(64, (3, 3),\n",
    "                            padding='same',\n",
    "                            activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (2, 2),\n",
    "                            padding='same',\n",
    "                            activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(128, (2, 2),\n",
    "                            padding='same',\n",
    "                            activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(128, (2, 2),\n",
    "                            padding='same',\n",
    "                            activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(256,activation= 'relu'))\n",
    "\n",
    "    model.add(layers.Dense(10,activation= 'relu'))\n",
    "\n",
    "    model.add(layers.Dense(2, activation='linear'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = init_model_cnnlog(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca828d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compiled(model):\n",
    "    model.compile(loss= 'mse',\n",
    "                  optimizer = 'adam',\n",
    "                  metrics=['mse'] )\n",
    "    return model\n",
    "model = model_compiled(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e86b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def model_train (model, X_train, y_train, batch_size=32 ,epochs=50, verbose=1):\n",
    "#     es = EarlyStopping(patience=5,\n",
    "#                        restore_best_weights=True)\n",
    "\n",
    "#     history = model.fit(X_train,\n",
    "#                         y_train,\n",
    "#                         batch_size=batch_size,\n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=[X_val, y_val],\n",
    "#                         callbacks=[es],\n",
    "#                         verbose=verbose)\n",
    "#     return history\n",
    "\n",
    "# history = model_train(model_compi, X_train, y_train)\n",
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d852a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[0].set_ylim(0,10)\n",
    "    ax[1].set_title('mse')\n",
    "    ax[1].plot(history.epoch, history.history[\"mse\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_mse\"], label=\"Validation ,mse\")\n",
    "    ax[1].set_ylim(0,10)\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b31d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2262c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# es = EarlyStopping(patience=5,\n",
    "#                     restore_best_weights=True)\n",
    "\n",
    "# history = model_compi.fit(X_train,\n",
    "#                     y_train,\n",
    "#                     batch_size=32,\n",
    "#                     epochs=50,\n",
    "#                     validation_data=[X_val, y_val],\n",
    "#                     callbacks=[es],\n",
    "#                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8c8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_compi.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06290e33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my_pred\u001b[49m\u001b[38;5;241m.\u001b[39mshape, y_test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af075951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 163ms/step - loss: 292698.4062 - mse: 292698.4062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[292698.40625, 292698.40625]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7324fb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "🏋️ Starting model training ...\u001b[0m\n",
      "\u001b[34m\n",
      "Training model...\u001b[0m\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 7: early stopping\n",
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfyl8q_26/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfyl8q_26/model/data/model/assets\n",
      "2025/06/04 15:03:19 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained with min val MSE: 37456.8\n",
      "✅ Results saved on mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpafwno0e8/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpafwno0e8/model/data/model/assets\n",
      "Successfully registered model 'reg on x,y - best_slice'.\n",
      "2025/06/04 15:03:28 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: reg on x,y - best_slice, version 1\n",
      "Created version '1' of model 'reg on x,y - best_slice'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to mlflow\n",
      "✅ Model reg on x,y - best_slice (version 1) transitioned from None to staging\n",
      "✅ train() done \n",
      "\n",
      "✅ mlflow_run auto-log done\n"
     ]
    }
   ],
   "source": [
    "from src.ml_logic.interface import train\n",
    "\n",
    "train(model, X_train, y_train, 'pos2D', 'best_slice', 'reg on x,y - best_slice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083a3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_flag_mot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
