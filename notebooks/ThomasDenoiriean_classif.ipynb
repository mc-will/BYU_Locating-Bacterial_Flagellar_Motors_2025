{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjaWqWF1QSsE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PB_E-PzQe0j",
        "outputId": "3218078a-9da2-4780-8020-a1c0f1fc4085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "6e0ATnDWQjoy",
        "outputId": "0a7aaa06-bd21-4d34-be59-5ccce6e910e5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 155,\n        \"min\": 335,\n        \"max\": 646,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          470,\n          335,\n          646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"row_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 221,\n        \"min\": 275,\n        \"max\": 717,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          275,\n          717,\n          469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tomo_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"tomo_5f235a\",\n          \"tomo_f8b46e\",\n          \"tomo_a5ac23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Motor_axis_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.784887978899608,\n        \"min\": 119.0,\n        \"max\": 169.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          119.0,\n          123.0,\n          169.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Motor_axis_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.05409355338192,\n        \"min\": 574.0,\n        \"max\": 728.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          656.0,\n          728.0,\n          574.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Motor_axis_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 307.8901319193802,\n        \"min\": 352.0,\n        \"max\": 895.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          372.0,\n          352.0,\n          895.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Array_shape_axis_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 300,\n        \"max\": 300,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          300\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Array_shape_axis_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 928,\n        \"max\": 960,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          960\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Array_shape_axis_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 928,\n        \"max\": 928,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Voxel_spacing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4433756729740643,\n        \"min\": 13.1,\n        \"max\": 15.6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          15.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number_of_motors\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b41b9bc5-423a-472c-9b19-36b0d7e3df73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>row_id</th>\n",
              "      <th>tomo_id</th>\n",
              "      <th>Motor_axis_0</th>\n",
              "      <th>Motor_axis_1</th>\n",
              "      <th>Motor_axis_2</th>\n",
              "      <th>Array_shape_axis_0</th>\n",
              "      <th>Array_shape_axis_1</th>\n",
              "      <th>Array_shape_axis_2</th>\n",
              "      <th>Voxel_spacing</th>\n",
              "      <th>Number_of_motors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>470</td>\n",
              "      <td>275</td>\n",
              "      <td>tomo_5f235a</td>\n",
              "      <td>119.0</td>\n",
              "      <td>656.0</td>\n",
              "      <td>372.0</td>\n",
              "      <td>300</td>\n",
              "      <td>960</td>\n",
              "      <td>928</td>\n",
              "      <td>13.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>335</td>\n",
              "      <td>717</td>\n",
              "      <td>tomo_f8b46e</td>\n",
              "      <td>123.0</td>\n",
              "      <td>728.0</td>\n",
              "      <td>352.0</td>\n",
              "      <td>300</td>\n",
              "      <td>928</td>\n",
              "      <td>928</td>\n",
              "      <td>13.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>646</td>\n",
              "      <td>469</td>\n",
              "      <td>tomo_a5ac23</td>\n",
              "      <td>169.0</td>\n",
              "      <td>574.0</td>\n",
              "      <td>895.0</td>\n",
              "      <td>300</td>\n",
              "      <td>959</td>\n",
              "      <td>928</td>\n",
              "      <td>15.6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b41b9bc5-423a-472c-9b19-36b0d7e3df73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b41b9bc5-423a-472c-9b19-36b0d7e3df73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b41b9bc5-423a-472c-9b19-36b0d7e3df73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b693c351-74d2-4d16-99e7-4408b7308a9b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b693c351-74d2-4d16-99e7-4408b7308a9b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b693c351-74d2-4d16-99e7-4408b7308a9b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Unnamed: 0  row_id      tomo_id  Motor_axis_0  Motor_axis_1  \\\n",
              "470         470     275  tomo_5f235a         119.0         656.0   \n",
              "335         335     717  tomo_f8b46e         123.0         728.0   \n",
              "646         646     469  tomo_a5ac23         169.0         574.0   \n",
              "\n",
              "     Motor_axis_2  Array_shape_axis_0  Array_shape_axis_1  Array_shape_axis_2  \\\n",
              "470         372.0                 300                 960                 928   \n",
              "335         352.0                 300                 928                 928   \n",
              "646         895.0                 300                 959                 928   \n",
              "\n",
              "     Voxel_spacing  Number_of_motors  \n",
              "470           13.1                 1  \n",
              "335           13.1                 1  \n",
              "646           15.6                 2  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./drive/MyDrive/train_labels.csv')\n",
        "df.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSxi_HkoQsnq"
      },
      "outputs": [],
      "source": [
        "def select_tomo_ids(df, number_of_slices=[300], number_of_motors=[0, 1], y_shape_range=(924, 960), x_shape_range=(924, 960)) -> pd.Series:\n",
        "    '''\n",
        "    Return the list of the tomo_ids obtained by filtering the DataFrame base on the given parameters\n",
        "\n",
        "            Parameters:\n",
        "                    df (pd.Dataframe): the dataset to filter\n",
        "                    number_of_slices (list:int): number of slices per tomogram\n",
        "                    max_number_of_motors (list:int): max number of motors\n",
        "                    y_shape_range(tuple:int): tuple of the (min, max) y size of pictures\n",
        "                    x_shape_range(tuple:int): tuple of the (min, max) x size of pictures\n",
        "\n",
        "            Returns:\n",
        "                    pd.Series: pandas Series of the tomo_ids corresponding to the filter\n",
        "    '''\n",
        "    df = df[(df['Array_shape_axis_1'] >= y_shape_range[0]) & (df['Array_shape_axis_2'] <= y_shape_range[1])]\n",
        "    df = df[(df['Array_shape_axis_1'] >= x_shape_range[0]) & (df['Array_shape_axis_2'] <= x_shape_range[1])]\n",
        "    df = df[(df['Array_shape_axis_0'].isin(number_of_slices)) & (df['Number_of_motors'].isin(number_of_motors))]\n",
        "\n",
        "\n",
        "    return df.tomo_id\n",
        "\n",
        "\n",
        "def selection_images_labels(df, dir_images, num_slices=[300], num_motors=[1]):\n",
        "\n",
        "    ''''\n",
        "    function to return the path to the selected images (which type, which tomos, how many motors,\n",
        "    shape of the images)\n",
        "    Parameters:\n",
        "    ----------\n",
        "    df = database (train)\n",
        "    dir_images(str) = directory with the images we want to feed to the model\n",
        "    num_slices, num_motors, y_shape_range, x_shape_range = params for the select_tomo_ids function\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    filtered_image_paths (list or np.array): List of image paths.\n",
        "\n",
        "    labels (np.array or list): Corresponding labels.\n",
        "    '''\n",
        "\n",
        "   # Step 1: Filter tomos\n",
        "    tomo_ids = select_tomo_ids(df, number_of_slices=num_slices, number_of_motors=num_motors)\n",
        "    df_select = df[df['tomo_id'].isin(tomo_ids)].copy()\n",
        "\n",
        "    # Step 2: Set up labels\n",
        "    df_select['motor_coord'] = df_select.apply(lambda row: (row['Motor_axis_2'], row['Motor_axis_1']), axis=1)\n",
        "\n",
        "    # Step 3: Load all images\n",
        "    dir_mean_image = f'./drive/MyDrive/{dir_images}'\n",
        "    all_images = glob.glob(os.path.join(dir_mean_image, '**', '*.jpg'), recursive=True)\n",
        "\n",
        "    print(f\"Found {len(all_images)} images in {dir_mean_image}\")\n",
        "\n",
        "    # Step 4: Match images using substring matching\n",
        "    filtered_image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in df_select.iterrows():\n",
        "        tomo_id = row['tomo_id']\n",
        "        matched = [p for p in all_images if tomo_id in os.path.basename(p)]\n",
        "\n",
        "        if matched:\n",
        "            filtered_image_paths.append(matched[0])  # If multiple, take the first\n",
        "            labels.append(row['Number_of_motors'])\n",
        "        else:\n",
        "            print(f\"⚠️ No image found for tomo_id: {tomo_id}\")\n",
        "\n",
        "    print(f\"Matched {len(filtered_image_paths)} image-label pairs\")\n",
        "\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    return filtered_image_paths, labels\n",
        "\n",
        "\n",
        "# Define image reading function\n",
        "def read_img_jpg(path, label):\n",
        "    \"\"\"\n",
        "    Reads a JPEG image from a file path, decodes it as a grayscale image (1 channel),\n",
        "    normalizes pixel values to the range [0, 1], and returns it along with its label.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    path : tf.Tensor\n",
        "        A scalar string tensor representing the file path to the JPEG image.\n",
        "\n",
        "    label : tf.Tensor or any\n",
        "        The label associated with the image (e.g., coordinates or class ID).\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    img : tf.Tensor\n",
        "        A 3D float32 tensor of shape (height, width, 1) representing the normalized image.\n",
        "\n",
        "    label : same as input\n",
        "        The original label passed in, unchanged.\n",
        "    \"\"\"\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=1)\n",
        "    img = tf.cast(img, tf.float32) / 255.0  # normalize to [0, 1]\n",
        "    return img, label\n",
        "\n",
        "\n",
        "\n",
        "def batches_images_ram(\n",
        "    read_img_jpg,\n",
        "    filtered_image_paths,\n",
        "    labels,\n",
        "    shuffle=True,\n",
        "    batch_size=32,\n",
        "    split=False,\n",
        "    val_fraction=0.2,\n",
        "    test_fraction=0.2,\n",
        "    seed=42\n",
        "):\n",
        "    \"\"\"\n",
        "    Load images and labels as tf.data.Dataset, optionally shuffle and batch,\n",
        "    and optionally split into train/val/test datasets.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    read_img_jpg : function\n",
        "        Function to load and preprocess image from path.\n",
        "\n",
        "    filtered_image_paths : list or np.array\n",
        "        List of image paths.\n",
        "\n",
        "    labels : np.array or list\n",
        "        Corresponding labels.\n",
        "\n",
        "    shuffle : bool, default=True\n",
        "        Whether to shuffle the dataset.\n",
        "\n",
        "    batch_size : int, default=32\n",
        "        Batch size.\n",
        "\n",
        "    split : bool, default=False\n",
        "        Whether to split dataset into train/val/test.\n",
        "\n",
        "    val_fraction : float, default=0.2\n",
        "        Fraction of data for validation.\n",
        "\n",
        "    test_fraction : float, default=0.2\n",
        "        Fraction of data for testing.\n",
        "\n",
        "    seed : int, default=42\n",
        "        Random seed for shuffling.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    If split=False:\n",
        "        dataset : tf.data.Dataset\n",
        "            Dataset with (image, label) pairs, batched and optionally shuffled.\n",
        "\n",
        "    If split=True:\n",
        "        train_ds, val_ds, test_ds : tf.data.Dataset\n",
        "            The three splits, all batched and shuffled as specified.\n",
        "    \"\"\"\n",
        "\n",
        "    dataset_size = len(filtered_image_paths)\n",
        "    # Combine and optionally shuffle the data as a list of tuples\n",
        "    data = list(zip(filtered_image_paths, labels))\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(data)\n",
        "\n",
        "    # Unzip the shuffled data back\n",
        "    filtered_image_paths, labels = zip(*data)\n",
        "\n",
        "    # Convert back to lists or arrays\n",
        "    filtered_image_paths = list(filtered_image_paths)\n",
        "    labels = list(labels)\n",
        "\n",
        "    if split:\n",
        "        # Compute sizes\n",
        "        val_size = int(val_fraction * dataset_size)\n",
        "        test_size = int(test_fraction * dataset_size)\n",
        "        train_size = dataset_size - val_size - test_size\n",
        "\n",
        "        # Split into slices\n",
        "        test_paths = filtered_image_paths[:test_size]\n",
        "        print(test_paths)\n",
        "        test_labels = labels[:test_size]\n",
        "\n",
        "        val_paths = filtered_image_paths[test_size:test_size + val_size]\n",
        "        print(val_paths)\n",
        "        val_labels = labels[test_size:test_size + val_size]\n",
        "\n",
        "        train_paths = filtered_image_paths[test_size + val_size:]\n",
        "        print(train_paths)\n",
        "        train_labels = labels[test_size + val_size:]\n",
        "\n",
        "        # Create tf.data.Dataset for each\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels)).map(read_img_jpg).batch(batch_size)\n",
        "        val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels)).map(read_img_jpg).batch(batch_size)\n",
        "        test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels)).map(read_img_jpg).batch(batch_size)\n",
        "\n",
        "        return train_ds, val_ds, test_ds #, test_paths, test_labels\n",
        "\n",
        "    else:\n",
        "        # Single dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((filtered_image_paths, labels))\n",
        "        dataset = dataset.map(read_img_jpg).batch(batch_size)\n",
        "        return dataset, filtered_image_paths, labels\n",
        "\n",
        "\n",
        "def plot_history_regression(history, xlims=None, ylims=None):\n",
        "    '''\n",
        "    Function to plot learning curves for a regression task\n",
        "    Parameters:\n",
        "        history: output from a model.fit\n",
        "        xlims,ylims (tuple of float, optional): limits for x and y axes, if not\n",
        "                                                provided are defined as\n",
        "                                                (0,max(epochs)), (0,max(loss))\n",
        "    '''\n",
        "    if xlims is None:\n",
        "        xlims = (0, max(history.epoch))\n",
        "    if ylims is None:\n",
        "        ylims = (0, max(history.history['loss']))\n",
        "    print(xlims,ylims)\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
        "    ax[0].set_title('loss')\n",
        "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
        "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
        "    ax[0].set_ylim(ylims)\n",
        "    ax[0].set_xlim(xlims)\n",
        "    ax[0].set_xlabel('Epochs')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "\n",
        "    ax[1].set_title('recall loss')\n",
        "    ax[1].plot(history.epoch, history.history[\"recall\"], label=\"Train recall\")\n",
        "    ax[1].plot(history.epoch, history.history[\"val_recall\"], label=\"Validation recall\")\n",
        "    ax[1].set_ylim(ylims)\n",
        "    ax[1].set_xlim(xlims)\n",
        "    ax[1].set_xlabel('Epochs')\n",
        "    ax[1].set_ylabel('recall')\n",
        "    ax[0].legend()\n",
        "    ax[1].legend()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qcoCvUFQ0Bv"
      },
      "outputs": [],
      "source": [
        "def generate_base_data():\n",
        "  all_slices_number = df['Array_shape_axis_0'].unique()\n",
        "\n",
        "  filtered_image_paths,labels = selection_images_labels(df, 'adaptequal_1_padded', num_slices=list(all_slices_number), num_motors=[0, 1])\n",
        "\n",
        "  train_ds, val_ds, test_ds = batches_images_ram(\n",
        "      read_img_jpg,\n",
        "      filtered_image_paths,\n",
        "      labels,\n",
        "      shuffle=True,\n",
        "      batch_size=32,\n",
        "      split=True,\n",
        "      val_fraction=0.2,\n",
        "      test_fraction=0.2,\n",
        "      seed=42)\n",
        "\n",
        "  return train_ds, val_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGmBVs_MQ_uS",
        "outputId": "3ead05ff-ae0e-4fea-e2ca-da87a7d8b333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 648 images in ./drive/MyDrive/adaptequal_1_padded\n",
            "Matched 578 image-label pairs\n",
            "['./drive/MyDrive/adaptequal_1_padded/tomo_dae195.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f2fa4a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cabaa0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f7f28b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ed1c97.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ff505c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8f4d60.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2aeb29.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_651ecd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e96200.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0d4c9e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2dcd5c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_983fce.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7b1ee3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8b6795.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_dcb9b4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e764a7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e26c6b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_331130.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f8b835.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_746d88.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9cd09e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b9eb9a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cf0875.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7cf523.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fd41c4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_54e1a7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ca472a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6478e5.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e9b7f2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_247826.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_675583.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f0adfc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_378f43.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_19a313.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_172f08.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f3e449.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3b83c7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8c13d9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2c607f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c11e12.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_412d88.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4b124b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_38c2a6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ec1314.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1c38fd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e63ab4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f07244.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_210371.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d6e3c7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_935f8a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a4c52f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a46b26.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fadbe2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b28579.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_35ec84.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_369cce.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6c203d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b80310.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_640a74.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_22976c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d21396.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ecbc12.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_040b80.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_85708b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b98cf6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e1e5d3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_138018.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3264bc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e50f04.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d723cd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2a6ca2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1f0e78.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_67565e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fd5b38.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_05b39c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_372a5c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c3619a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ba76d8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a67e9f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a6646f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_db656f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4102f1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bb5ac1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4ed9de.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_61e947.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1da0da.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_821255.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3e7783.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c84b46.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_974fd4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_444829.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b50c0f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2a6091.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fa5d78.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bdd3a0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1c2534.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d916dc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bdc097.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7036ee.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cacb75.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5b359d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7fa3b1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_049310.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_dd36c9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e3864f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0a8f05.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ff7c20.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0fab19.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1c75ac.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d0699e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1e9980.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4ee35e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6943e6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_99a3ce.jpg']\n",
            "['./drive/MyDrive/adaptequal_1_padded/tomo_6f2c1f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_dfc627.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8d5995.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cc2b5c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_50cbd9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a72a52.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9ae65f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9c0253.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_66285d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_47d380.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_98686a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4077d8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_97a2c6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ba9b3d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e2a336.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_aaa1fd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e8db69.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_532d49.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f94504.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5e2a91.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2fc82d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_16fce8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_401341.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0333fa.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a81e01.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b87c8e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e61cdf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b2ebbc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_10c564.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f71c16.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_47ac94.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fea6e8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c00ab5.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_823bc7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_278194.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2fb12d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a537dd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_19a4fd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_417e5f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_81445c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_317656.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7fbc49.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_806a8f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ab804d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_957567.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8634ee.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fc1665.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_63e635.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2645a0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5984bf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fc3c39.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_101279.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_08a6d6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0c2749.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6607ec.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_23ce49.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ca1d13.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e55f81.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bfd5ea.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d7475d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_136c8d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c4db00.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ea3f3a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ef1a1a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2dd6bd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_82d780.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bede89.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d5465a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e71210.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9f1828.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7550f4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_efe1f8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bd42fa.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_01a877.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_59b470.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0c3d78.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d0c025.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0eb41e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ca8be0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_dbc66d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_84997e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5dd63d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b9088c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_24795a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6521dc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_676744.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cff77a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6f83d4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f78e91.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6303f0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_997437.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cae587.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9aee96.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_be9b98.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_97876d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e2da77.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_081a2d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cb5ec6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fc5ae4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4925ee.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_38d285.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_79a385.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4469a7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_05f919.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_568537.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_71ece1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_85fa87.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bcb115.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2cace2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b4d92b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cc3fc4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_94c173.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a2a928.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_375513.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_40b215.jpg']\n",
            "['./drive/MyDrive/adaptequal_1_padded/tomo_c6f50a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_288d4f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_229f0a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_decb81.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_39b15b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_466489.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d8c917.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_736dfa.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_03437b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_066095.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_935ae0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c10f64.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8e4919.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2bb588.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5bb31c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_692081.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ba37ec.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_20a9ed.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b2b342.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d396b5.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b54396.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_122a02.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4e3e37.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9f918e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6cb0f0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f36495.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e81143.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6acb9e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_56b9a3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_dfdc32.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_98d455.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2483bb.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e5a091.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_91beab.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b18127.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_73173f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_221a47.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5f1f0c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_24a095.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_60d478.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4f5a7b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_975287.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_072a16.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a8bf76.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_399bd9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_512f98.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4e38b8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_146de2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_423d52.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_711fad.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b03f81.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_62dbea.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a2bf30.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_25780f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8f5995.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_191bcb.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_372690.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cf5bfc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f1bf2f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c678d9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cf53d0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c13fbf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e0739f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6d22d1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_57c814.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_13973d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_518a1f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_dee783.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_556257.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b11ddc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8e8368.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e9fa5f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c649f8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_517f70.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_622ca9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ac9fef.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_46250a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7eb641.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bfdf19.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6bb452.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_616f0b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f672c0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4c2e4e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9d3a0e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_225d8f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d96d6e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5f34b3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_93c0b4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_464108.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8554af.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b24f1a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_648adf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b7d94c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9ed470.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_db4517.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3b8291.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f427b3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f76529.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5b087f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bc143f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_774aae.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b0e5c6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2f3261.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b93a2d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ab78d0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c7b008.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5764d6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2b996c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5308e8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e1a034.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_672101.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0e9757.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_134bb0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_643b20.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d3bef7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f6de9b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8e58f1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4d528f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e72e60.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0fe63f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a0cb00.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_221c8e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e57baf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_02862f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_738500.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_17143f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1446aa.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0c3a99.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8e4f7d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_891afe.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d0d9b6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_aff073.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0308c5.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_db2a10.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d634b7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_813916.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_30d4e5.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6f0ee4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_23c8a4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4f379f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_37076e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_37c426.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fbb49b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e7c195.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_455dcd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fd9357.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3eb9c8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cd1a7c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_16136a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6a84b7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_918e2b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c36b4b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f871ad.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_df866a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6733fa.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3c6038.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_85edfd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4e41c2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9fc2b6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_05df8a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7f0184.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1cc887.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_06e11e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_16efa8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8d231b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_78b03d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_32aaa7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1fb6a7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ac4f0d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_971966.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fb6ce6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_50f0bf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_285454.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4b59a2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_69d7c9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3183d2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2c9da1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d23087.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3b7a22.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4baff0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_adc026.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e5ac94.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_307f33.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_94a841.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_285d15.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6bc974.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_51a47f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1dc5f9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7e3494.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_08bf73.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0eb994.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7dc063.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_79756f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6c5a26.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_76a42b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fb08b5.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_139d9e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e32b81.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_12f896.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1af88d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_603e40.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f82a15.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0f9df0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_539259.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fe85f6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_fe050c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d31c96.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c38e83.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b10aa4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d83ff4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d5aa20.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bbe766.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_305c97.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5b8db4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5d798e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c8f3ce.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_881d84.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_da38ea.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d0aa3b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_abac2e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_183270.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_51a77e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_516cdd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c9d07c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_656915.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7dcfb8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a4f419.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c4bfe2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_eb4fd4.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1ab322.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6b1fd3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9dbc12.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8e30f5.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_033ebe.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a3ed10.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4555b6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6e237a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5b34b2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3e6ead.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_891730.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6df2d6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_769126.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_95c0eb.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bebadf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_5f235a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3a3519.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_23a8e8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_651ec2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3b1cc9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_91c84c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a1a9a3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8ee8fd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_28f9c1.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_67ff4e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_acadd7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d2b1bc.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_53e048.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a75c98.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_abb45a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_493bea.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0363f2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2c8ea2.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_30b580.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a37a5c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_569981.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d84544.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e685b8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_ede779.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b8595d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_180bfd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4e478f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c596be.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_89d156.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9f424e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_71d2c0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_646049.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_13484c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_95e699.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c36baf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9f222a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_72b187.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6a6a3b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_91031e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_abbd3b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_7a9b64.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_868255.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_1efc28.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_319f79.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_256717.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_72763e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_385eb6.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_3a0914.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e34af8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4c1ca8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2acf68.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_24fda8.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bad724.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e51e5e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_4e1b18.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_374ca7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9674bf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_098751.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c925ee.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bde7f3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_122c46.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_53c71b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e2ccab.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_68e123.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9986f0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8e90f9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_cc65a9.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_57592d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_80bf0f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d9a2af.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_00e047.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2a89bb.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c4a4bb.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0da370.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_6c4df3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_47c399.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9997b3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_db6051.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_510f4e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_60ddbd.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_bb9df3.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_79d622.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_499ee0.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_087d64.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_49f4ee.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_f8b46e.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d2339b.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2e1f4c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_2c9f35.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_0a180f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a910fe.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_9cde9d.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b7becf.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d6c63f.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_be4a3a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_c46d3c.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_161683.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_a020d7.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b4d9da.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_513010.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_8f063a.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_b8f096.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_e77217.jpg', './drive/MyDrive/adaptequal_1_padded/tomo_d26fcb.jpg']\n"
          ]
        }
      ],
      "source": [
        "train_ds, val_ds, test_ds = generate_base_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBF3qes1RBvQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def train_model():\n",
        "    IMG_SIZE = 224\n",
        "\n",
        "    input_tensor = Input(shape=(960, 960, 1), name=\"grayscale_input\")\n",
        "\n",
        "    # Resize et conversion N&B -> RGB\n",
        "    x = layers.Resizing(IMG_SIZE, IMG_SIZE)(input_tensor)\n",
        "    x = layers.Conv2D(3, (3, 3), padding='same')(x)\n",
        "\n",
        "    backbone = Xception(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    backbone.trainable = False  # gel du backbone\n",
        "\n",
        "    #for layer in backbone.layers[:-2]:\n",
        "    #    layer.trainable = False\n",
        "\n",
        "    x = backbone(x)\n",
        "\n",
        "    # Flatten + Dense\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(5, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Sortie des keypoints\n",
        "    out = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=out)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'recall'])\n",
        "\n",
        "    # Callback early stopping\n",
        "    es = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=1)\n",
        "\n",
        "    # Entraînement\n",
        "    history = model.fit(train_ds, validation_data=val_ds, epochs=200, callbacks=[es])\n",
        "\n",
        "    plot_history_regression(history)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zidxX34chzMH",
        "outputId": "3f9159c5-ad01-4822-9666-e18d580e7165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.1.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting mlflow-skinny==3.1.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.1.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.1)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<21,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.41)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.1.0->mlflow)\n",
            "  Downloading databricks_sdk-0.56.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (0.115.12)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (8.7.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.1.0->mlflow)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.1.0->mlflow)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (2.11.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (4.14.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==3.1.0->mlflow) (0.34.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.4.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.2)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==3.1.0->mlflow) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.0->mlflow) (3.22.0)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.0->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow) (2025.4.26)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==3.1.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.0->mlflow) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==3.1.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.1.0-py3-none-any.whl (24.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.56.0-py3-none-any.whl (733 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m733.7/733.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gunicorn, graphql-core, opentelemetry-api, graphql-relay, docker, alembic, opentelemetry-semantic-conventions, graphene, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed alembic-1.16.1 databricks-sdk-0.56.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-3.1.0 mlflow-skinny-3.1.0 opentelemetry-api-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFkkSQG4lwRf"
      },
      "outputs": [],
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for batch_x, batch_y in test_ds:\n",
        "    X_test.append(batch_x.numpy())\n",
        "    y_test.append(batch_y.numpy())\n",
        "\n",
        "# Fusionner les batches\n",
        "X_test = np.concatenate(X_test, axis=0)\n",
        "y_test = np.concatenate(y_test, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp9PxsWZ_BOy",
        "outputId": "8c1ae700-d28d-4c04-847a-114130f73d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Epoch 1/200\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 21s/step - accuracy: 0.5800 - loss: 2.9656 - recall: 0.6298 - val_accuracy: 0.6783 - val_loss: 2.2536 - val_recall: 0.9833\n",
            "Epoch 2/200\n",
            "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 20s/step - accuracy: 0.6562 - loss: 2.2658 - recall: 1.0000"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "mlflow.set_tracking_uri(\"http://34.79.119.176:5000\")\n",
        "\n",
        "mlflow.set_experiment(\"test_experiment_colab\")  # créé si inexistant\n",
        "\n",
        "with mlflow.start_run():\n",
        "    model, history = train_model()\n",
        "\n",
        "    # Enregistrer le modèle\n",
        "    mlflow.tensorflow.log_model(model, artifact_path=\"model\")\n",
        "\n",
        "    # Enregistrer des métriques\n",
        "    loss, acc, recall = model.evaluate(X_test, y_test, verbose=0)\n",
        "    mlflow.log_metric(\"test_loss\", loss)\n",
        "    mlflow.log_metric(\"test_accuracy\", acc)\n",
        "    mlflow.log_metric(\"test_recall\", acc)\n",
        "\n",
        "    mlflow.log_param(\"model_architecture\", \"Xception\")\n",
        "    mlflow.log_param(\"epochs\", 200)\n",
        "    mlflow.log_param(\"batch_size\", 32)\n",
        "    mlflow.log_param(\"early_stopping\", True)\n",
        "    mlflow.log_param(\"loss_function\", model.loss)\n",
        "    mlflow.log_param(\"optimizer\", type(model.optimizer).__name__)\n",
        "    mlflow.log_param(\"learning_rate\", model.optimizer.learning_rate.numpy())\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Si y_pred est un vecteur de probabilités (ex : pour une classe binaire)\n",
        "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    fbeta = fbeta_score(y_test, y_pred_labels, beta=2)\n",
        "\n",
        "    mlflow.log_metric(\"test_fbeta\", fbeta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sUSXV0hBK1K"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Si y_pred est un vecteur de probabilités (ex : pour une classe binaire)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "from sklearn.metrics import fbeta_score\n",
        "sklearn_score = fbeta_score(y_test, y_pred_labels, beta=2)\n",
        "\n",
        "model.evaluate(X_test, y_test, verbose=0), sklearn_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtgjK_mrahE7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_pred_labels, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzWXZUqVSQBp"
      },
      "outputs": [],
      "source": [
        "from re import M\n",
        "import os\n",
        "\n",
        "X_pred = []\n",
        "\n",
        "for picture in sorted(os.listdir('./drive/MyDrive/tomo_00e047')):\n",
        "    t = img.imread(f'./drive/MyDrive/tomo_00e047/{picture}')/255\n",
        "    t = tf.expand_dims(t, -1)\n",
        "    t = tf.image.resize(t, [960,960])\n",
        "    t = tf.expand_dims(t, axis=0)\n",
        "    X_pred.append(float(model.predict(t , verbose=0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSoiuO9zWVQ3"
      },
      "outputs": [],
      "source": [
        "best_slice = np.argmax(X_pred)\n",
        "\n",
        "\n",
        "best_slice, X_pred[best_slice]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhqcrEL7V0gl"
      },
      "outputs": [],
      "source": [
        "X_pred[169]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN0gALnHqvXf"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11f6NEi0xoQr"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anmv4pnmqos6"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# A masker that will mask out partitions of the input image\n",
        "masker = shap.maskers.Image(\"blur(960,960)\", X_test[0].shape)\n",
        "\n",
        "# Finally create the explainer\n",
        "explainer = shap.Explainer(model, masker)\n",
        "\n",
        "# Explain some images using 500 evaluations of the model\n",
        "# to estimate the SHAP values\n",
        "shap_values = explainer(X_test[15:20], max_evals=500, batch_size=50,\n",
        "                        outputs=shap.Explanation.argsort.flip[:4],\n",
        "                        silent=True)# A masker that will mask out partitions of the input image\n",
        "masker = shap.maskers.Image(\"blur(960,960)\", X_test[0].shape)\n",
        "\n",
        "# Finally create the explainer\n",
        "explainer = shap.Explainer(model, masker)\n",
        "\n",
        "# Explain some images using 500 evaluations of the model\n",
        "# to estimate the SHAP values\n",
        "shap_values = explainer(X_test[15:20], max_evals=500, batch_size=50,\n",
        "                        outputs=shap.Explanation.argsort.flip[:4],\n",
        "                        silent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XRYgbZHrXBD"
      },
      "outputs": [],
      "source": [
        "shap.image_plot(shap_values, pixel_values=X_test[1:5], width=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSmlNVIvv7Ud"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report([1 if pred >=0.5 else 0 for pred in y_pred], y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5ttMre5dmf6"
      },
      "outputs": [],
      "source": [
        "X_test"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}