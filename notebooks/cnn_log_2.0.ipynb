{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wm/.pyenv/versions/3.10.6/envs/byu/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/wm/.pyenv/versions/3.10.6/envs/byu/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Loading TensorFlow...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential, Input, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow_addons.metrics import FBetaScore\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.metrics import Recall, Precision\n",
    "\n",
    "from utils.data import get_best_slice, select_tomo_ids, get_csv_from_bq\n",
    "from utils.render_motor_position import get_motor_coordinates, get_slice_file_path\n",
    "from ml_logic.interface import train_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_csv= '../data/csv_raw/train_labels.csv'\n",
    "# path_image= '../data/pictures_raw/train'\n",
    "path_image = '../data/pictures_process/adaptequal_1_padded'\n",
    "\n",
    "df = pd.read_csv(path_train_csv).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.serie with list of tomo (tomo_2dd6bd)\n",
    "tomogram_id= select_tomo_ids(df,\n",
    "                             number_of_slices= list(df['Array_shape_axis_0'].unique()) #[500, 800, 600, 300, 400, 494]\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the img in array, ready for input the model\n",
    "\n",
    "def load_images_by_ids(folder_path,\n",
    "                       tomo_ids,\n",
    "                       color_mode='grayscale',\n",
    "                       target_size=None\n",
    "                       ):\n",
    "\n",
    "    images = []\n",
    "    folder = Path(folder_path)\n",
    "\n",
    "    for tomo_id in tomo_ids:\n",
    "        img_file = folder / f\"{tomo_id}.jpg\"\n",
    "        if img_file.exists():\n",
    "            img = load_img(img_file, color_mode=color_mode, target_size=target_size)\n",
    "            img_array = img_to_array(img) / 255.0\n",
    "            images.append(img_array)\n",
    "        else:\n",
    "            print(f\"[‚ö†Ô∏è] Imagen no encontrada: {img_file}\")\n",
    "\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and y\n",
    "X = load_images_by_ids(path_image, tomogram_id)\n",
    "\n",
    "df_filtered = df[df['tomo_id'].isin(tomogram_id)]\n",
    "y = df_filtered['Number_of_motors']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - Val - test\n",
    "\n",
    "random_state=42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_model_densenet(X):\n",
    "    original_input_shape = X.shape[1:]\n",
    "\n",
    "    #  force input to 3 channel if it's grey (1 canal)\n",
    "    if original_input_shape[-1] == 1:\n",
    "        base_input_shape = original_input_shape[:-1] + (3,)\n",
    "    else:\n",
    "        base_input_shape = original_input_shape\n",
    "\n",
    "    # load DenseNet121 without last classify layer\n",
    "    base_model = DenseNet121(include_top=False,\n",
    "                             weights='imagenet',\n",
    "                             input_shape=base_input_shape\n",
    "                             )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Input layer\n",
    "    inputs = Input(shape=original_input_shape)\n",
    "\n",
    "    # convert in RGB if need it,\n",
    "    if original_input_shape[-1] == 1:\n",
    "        x = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            FBetaScore(num_classes=1,\n",
    "                       average='micro',\n",
    "                       beta=2.0),\n",
    "            Recall()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "üèãÔ∏è Starting model training ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/07 22:51:58 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 22:51:59.230301: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 398s 13s/step - loss: 0.8059 - accuracy: 0.5385 - fbeta_score: 0.8631 - recall: 0.4789 - val_loss: 0.8432 - val_accuracy: 0.4423 - val_fbeta_score: 0.7986 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 408s 14s/step - loss: 0.6618 - accuracy: 0.6261 - fbeta_score: 0.8631 - recall: 0.8046 - val_loss: 0.6811 - val_accuracy: 0.5962 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 451s 15s/step - loss: 0.6147 - accuracy: 0.6838 - fbeta_score: 0.8631 - recall: 0.7854 - val_loss: 0.6361 - val_accuracy: 0.6923 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 427s 14s/step - loss: 0.5574 - accuracy: 0.7201 - fbeta_score: 0.8631 - recall: 0.7854 - val_loss: 0.6297 - val_accuracy: 0.6923 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 424s 14s/step - loss: 0.5403 - accuracy: 0.7329 - fbeta_score: 0.8631 - recall: 0.8391 - val_loss: 0.6359 - val_accuracy: 0.6923 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 427s 14s/step - loss: 0.4999 - accuracy: 0.7799 - fbeta_score: 0.8631 - recall: 0.8851 - val_loss: 0.6190 - val_accuracy: 0.6923 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 423s 14s/step - loss: 0.5390 - accuracy: 0.7479 - fbeta_score: 0.8631 - recall: 0.8123 - val_loss: 0.6174 - val_accuracy: 0.6923 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 388s 13s/step - loss: 0.4918 - accuracy: 0.7692 - fbeta_score: 0.8631 - recall: 0.8429 - val_loss: 0.6349 - val_accuracy: 0.6923 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4860 - accuracy: 0.7607 - fbeta_score: 0.8631 - recall: 0.8544 Restoring model weights from the end of the best epoch: 7.\n",
      "30/30 [==============================] - 410s 14s/step - loss: 0.4860 - accuracy: 0.7607 - fbeta_score: 0.8631 - recall: 0.8544 - val_loss: 0.6237 - val_accuracy: 0.6923 - val_fbeta_score: 0.7986 - val_recall: 0.9565\n",
      "Epoch 9: early stopping\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/nr/0rc2wzzd26zd1tptqppt9kjr0000gn/T/tmpv02a_tbt/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/nr/0rc2wzzd26zd1tptqppt9kjr0000gn/T/tmpv02a_tbt/model/data/model/assets\n",
      "python(34226) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "2025/06/07 23:55:32 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/nr/0rc2wzzd26zd1tptqppt9kjr0000gn/T/tmpv02a_tbt/model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/06/07 23:55:32 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheack point matrics: dict_keys(['loss', 'accuracy', 'fbeta_score', 'recall', 'val_loss', 'val_accuracy', 'val_fbeta_score', 'val_recall'])\n",
      "‚úÖ Results saved on mlflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/nr/0rc2wzzd26zd1tptqppt9kjr0000gn/T/tmp2xyb9zbi/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/nr/0rc2wzzd26zd1tptqppt9kjr0000gn/T/tmp2xyb9zbi/model/data/model/assets\n",
      "python(34238) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "2025/06/07 23:56:18 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/nr/0rc2wzzd26zd1tptqppt9kjr0000gn/T/tmp2xyb9zbi/model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.0']. Set logging level to DEBUG to see the full traceback. \n",
      "\u001b[31m2025/06/07 23:56:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to mlflow\n",
      "‚úÖ Model model_densenet121 (version 1) transitioned from None to staging\n",
      "‚úÖ train() done \n",
      "\n",
      "‚úÖ mlflow_run auto-log done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'model_densenet121'.\n",
      "Created version '1' of model 'model_densenet121'.\n",
      "/Users/wm/code/mc-will/bacterial_motor/BYU_Locating-Bacterial_Flagellar_Motors_2025/notebooks/../src/ml_logic/registry.py:41: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  version = client.get_latest_versions(name=model_name, stages=[current_stage])\n",
      "/Users/wm/code/mc-will/bacterial_motor/BYU_Locating-Bacterial_Flagellar_Motors_2025/notebooks/../src/ml_logic/registry.py:47: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "model_densenet = init_model_densenet(X_train)\n",
    "history_densenet = train_classification(model=model_densenet,\n",
    "                                        X_train = X_train,\n",
    "                                        y_train = y_train,\n",
    "                                        X_val = X_val,\n",
    "                                        y_val = y_val,\n",
    "                                        model_type = 'classification',\n",
    "                                        preprocess_type ='adaptequela_1',\n",
    "                                        model_name= 'model_densenet121',\n",
    "                                        batch_size= 16,\n",
    "                                        patience = 2\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 59s 26s/step - loss: 0.5082 - accuracy: 0.7931 - fbeta_score: 0.8333 - recall: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5082195401191711,\n",
       " 0.7931034564971924,\n",
       " 0.8333333730697632,\n",
       " 0.9655172228813171]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_densenet.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history_densenet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fonction of grafic all the metrics and its val's\n",
    "# def plot_training_metrics(history):\n",
    "#     \"\"\"\n",
    "#    plot the metrics, even if there is not one of them into 'history'\n",
    "#     \"\"\"\n",
    "#     history_dict = history.history\n",
    "#     plotted = False\n",
    "\n",
    "#     def safe_plot(metric_name, color, linestyle='-'):\n",
    "#         nonlocal plotted\n",
    "#         if metric_name in history_dict:\n",
    "#             label = metric_name.replace('_', ' ')\n",
    "#             plt.plot(history_dict[metric_name], c=color, linestyle=linestyle, label=label)\n",
    "#             plotted = True\n",
    "\n",
    "#     # fbeta\n",
    "#     safe_plot('fbeta_score', 'r')\n",
    "#     safe_plot('val_fbeta_score', 'r', '--')\n",
    "\n",
    "#     # recall\n",
    "#     safe_plot('recall', 'g')\n",
    "#     safe_plot('val_recall', 'g', '--')\n",
    "#     safe_plot('recall_1', 'g')  # alternativa por si usa nombre autom√°tico\n",
    "#     safe_plot('val_recall_1', 'g', '--')\n",
    "\n",
    "#     # accuracy\n",
    "#     safe_plot('accuracy', 'black')\n",
    "#     safe_plot('val_accuracy', 'black', '--')\n",
    "\n",
    "#     # precision\n",
    "#     safe_plot('precision', 'blue')\n",
    "#     safe_plot('val_precision', 'blue', '--')\n",
    "\n",
    "#     if plotted:\n",
    "#         plt.title(\"Training Metrics\")\n",
    "#         plt.xlabel(\"Epoch\")\n",
    "#         plt.ylabel(\"Metric Value\")\n",
    "#         plt.legend()\n",
    "#         plt.grid(True)\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"‚ö†Ô∏è No se encontr√≥ ninguna m√©trica conocida para graficar.\")\n",
    "\n",
    "\n",
    "# plot_training_metrics(history_densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_densenet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fbeta_score\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# La pred dans set de validaci√≥n\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_val_pred_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_densenet\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m      5\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m (y_val_pred_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Cal F-beta ponder√©\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_densenet' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# La pred dans set de validaci√≥n\n",
    "y_val_pred_prob = model_densenet.predict(X_val)\n",
    "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Cal F-beta ponder√©\n",
    "fbeta = fbeta_score(y_val, y_val_pred, beta=2, average='binary')\n",
    "print(f\"F-beta score ponder√©(beta=2) en val: {fbeta:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_densenet121\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "models_info = client.search_registered_models()\n",
    "for model in models_info:\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
