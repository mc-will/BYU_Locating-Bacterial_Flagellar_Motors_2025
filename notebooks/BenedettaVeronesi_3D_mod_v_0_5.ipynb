{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6351b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_stack_z_with_2d_padding(\n",
    "    folder_path,\n",
    "    padded_folder_path=None,\n",
    "    xy_size=960,\n",
    "    target_depth=300,\n",
    "    pad_value=255\n",
    "):\n",
    "    \"\"\"\n",
    "    Pads 2D slices in a folder to (xy_size, xy_size) and stacks them into a 3D volume.\n",
    "    Optionally saves padded images to disk if `padded_folder_path` is given.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray: padded stack of shape (target_depth, xy_size, xy_size, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    def padd_picture(image_path, size):\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        new_img = Image.new('RGB', (size, size), (255, 255, 255))\n",
    "        new_img.paste(img, (0, 0))\n",
    "        return new_img\n",
    "\n",
    "    def numeric_sort_key(filename):\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return int(numbers[0]) if numbers else -1\n",
    "\n",
    "    # Get sorted image filenames\n",
    "    image_files = sorted(\n",
    "        [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))],\n",
    "        key=numeric_sort_key\n",
    "    )\n",
    "\n",
    "    padded_images = []\n",
    "\n",
    "    for file in image_files:\n",
    "        source_path = os.path.join(folder_path, file)\n",
    "        padded_img = padd_picture(source_path, xy_size)\n",
    "\n",
    "        # Save if a destination path is given\n",
    "        if padded_folder_path:\n",
    "            dest_path = os.path.join(padded_folder_path, file)\n",
    "            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "            padded_img.save(dest_path)\n",
    "\n",
    "        padded_images.append(np.array(padded_img))\n",
    "\n",
    "    stack = np.stack(padded_images, axis=0)  # (Z, xy_size, xy_size, 3)\n",
    "    current_depth = stack.shape[0]\n",
    "\n",
    "    if current_depth > target_depth:\n",
    "        raise ValueError(f\"Stack depth {current_depth} exceeds target {target_depth}\")\n",
    "\n",
    "    # Pad in Z-axis\n",
    "    pad_slices = target_depth - current_depth\n",
    "    if pad_slices > 0:\n",
    "        padding = np.full(\n",
    "            (pad_slices, xy_size, xy_size, 3),\n",
    "            fill_value=pad_value,\n",
    "            dtype=stack.dtype\n",
    "        )\n",
    "        stack = np.concatenate([stack, padding], axis=0)\n",
    "\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe189752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 960, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "padded_stack = pad_stack_z_with_2d_padding(\n",
    "    folder_path='../data/pictures_raw/train/tomo_fd41c4',\n",
    "    padded_folder_path='../data/pictures_process/train_process/tomo_fd41c4',\n",
    "    xy_size=960,\n",
    "    #target_depth=800,\n",
    "    #pad_value=255  # white background\n",
    ")\n",
    "\n",
    "print(padded_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb19a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_stack_and_label(tomo_folder, label, n_slices=300, img_size=(960, 960)):\n",
    "    \"\"\"\n",
    "    Load n_slices images from tomo_folder, stack them, and return with label.\n",
    "    Designed to be used inside a tf.py_function to work with tf.data.Dataset.\n",
    "\n",
    "    Args:\n",
    "        tomo_folder (tf.Tensor): Path to tomo folder as tf.string tensor.\n",
    "        label (tf.Tensor): Label tensor.\n",
    "        n_slices (int): Number of slices to load.\n",
    "        img_size (tuple): Target image size (H, W).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (stacked volume, label), where volume shape = (n_slices, H, W, 3)\n",
    "    \"\"\"\n",
    "\n",
    "    def _load(tomo_folder_path, label_value):\n",
    "        # tomo_folder_path is a byte string here, decode it\n",
    "        folder = tomo_folder_path.numpy().decode(),\n",
    "        print(folder)\n",
    "        print(type(folder))\n",
    "        slice_files = sorted([f for f in os.listdir(folder) if f.endswith('.jpg')])\n",
    "\n",
    "        slice_files = slice_files[:n_slices]\n",
    "\n",
    "        slices = []\n",
    "        for fname in slice_files:\n",
    "            path = os.path.join(folder, fname)\n",
    "            img = Image.open(path).convert('RGB').resize(img_size)\n",
    "            arr = np.array(img, dtype=np.float32) / 255.0\n",
    "            slices.append(arr)\n",
    "\n",
    "        # Pad if fewer slices than n_slices\n",
    "        if len(slices) < n_slices:\n",
    "            n_pad = n_slices - len(slices)\n",
    "            pad_img = np.ones((img_size[0], img_size[1], 3), dtype=np.float32)\n",
    "            slices.extend([pad_img] * n_pad)\n",
    "\n",
    "        stack = np.stack(slices, axis=0).astype(np.float32)  # shape: (n_slices, H, W, 3)\n",
    "\n",
    "        return stack, np.float32(label_value)\n",
    "\n",
    "    volume, labels = tf.py_function(_load, [tomo_folder, label], [tf.float32, tf.float32])\n",
    "\n",
    "    # Set static shape info so TensorFlow knows the output shape\n",
    "    volume.set_shape((n_slices, img_size[0], img_size[1], 3))\n",
    "    labels.set_shape(())\n",
    "\n",
    "    return volume, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14edff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_images_labels(df, num_slices=[300], num_motors=[0,1]):\n",
    "\n",
    "   # Step 3: Load parent directory and finding all subdirs\n",
    "    dir_mean_image = '../data/pictures_process/train_process/'\n",
    "    parent_dir = Path(dir_mean_image)\n",
    "    subdirs = [str(p) for p in parent_dir.iterdir() if p.is_dir()]\n",
    "    names = [p.name for p in parent_dir.iterdir() if p.is_dir()]\n",
    "\n",
    "   # Step 1: Filter tomos\n",
    "    #tomo_ids = 'tomo_0a8f05', 'tomo_0a180f', 'tomo_0c3a99', 'tomo_0c3d78'\n",
    "    tomo_ids = select_tomo_ids(df, number_of_slices=num_slices, number_of_motors=num_motors)\n",
    "    df_select = df[df['tomo_id'].isin(names)].copy()\n",
    "\n",
    "\n",
    "    # Step 4: Match subdirectories and labels\n",
    "    filtered_image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df_select.iterrows():\n",
    "        tomo_id = row['tomo_id']\n",
    "        matched = [p for p in subdirs if tomo_id in os.path.basename(p)]\n",
    "\n",
    "        if matched:\n",
    "            filtered_image_paths.append(matched[0])  # If multiple, take the first\n",
    "            labels.append(row['Number_of_motors'])\n",
    "        else:\n",
    "            print(f\"⚠️ No image found for tomo_id: {tomo_id}\")\n",
    "\n",
    "    print(f\"Matched {len(filtered_image_paths)} image-label pairs\")\n",
    "\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    return filtered_image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "514d3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_stack_images_ram(\n",
    "    filtered_image_paths,\n",
    "    labels,\n",
    "    shuffle=True,\n",
    "    batch_size=2,\n",
    "    split=True,\n",
    "    val_fraction=0.2,\n",
    "    test_fraction=0.2,\n",
    "    seed=42,\n",
    "    xy_size=960,\n",
    "    target_depth=800\n",
    "):\n",
    "    dataset_size = len(filtered_image_paths)\n",
    "    data = list(zip(filtered_image_paths, labels))\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rng.shuffle(data)\n",
    "\n",
    "    filtered_image_paths, labels = zip(*data)\n",
    "    filtered_image_paths = list(filtered_image_paths)\n",
    "    labels = list(labels)\n",
    "\n",
    "    if split:\n",
    "        val_size = 2#int(val_fraction * dataset_size)\n",
    "        test_size = 2#int(test_fraction * dataset_size)\n",
    "        train_size = dataset_size - val_size - test_size\n",
    "\n",
    "        test_paths = filtered_image_paths[:test_size]\n",
    "        test_labels = labels[:test_size]\n",
    "        val_paths = filtered_image_paths[test_size:test_size + val_size]\n",
    "        val_labels = labels[test_size:test_size + val_size]\n",
    "        train_paths = filtered_image_paths[test_size + val_size:]\n",
    "        train_labels = labels[test_size + val_size:]\n",
    "\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "        val_ds = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "        test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
    "\n",
    "        train_ds = train_ds.map(lambda x, y: load_stack_and_label(x, y, n_slices=target_depth, img_size=(xy_size, xy_size)),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size)\n",
    "\n",
    "        val_ds = val_ds.map(lambda x, y: load_stack_and_label(x, y, n_slices=target_depth, img_size=(xy_size, xy_size)),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size)\n",
    "\n",
    "        test_ds = test_ds.map(lambda x, y: load_stack_and_label(x, y, n_slices=target_depth, img_size=(xy_size, xy_size)),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size)\n",
    "\n",
    "        return train_ds, val_ds, test_ds, test_paths, test_labels\n",
    "\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filtered_image_paths, labels))\n",
    "        dataset = dataset.map(lambda x, y: load_stack_and_label(x, y,n_slices=target_depth, img_size=(xy_size, xy_size))).batch(batch_size)\n",
    "        return dataset, filtered_image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55b1c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>row_id</th>\n",
       "      <th>tomo_id</th>\n",
       "      <th>Motor_axis_0</th>\n",
       "      <th>Motor_axis_1</th>\n",
       "      <th>Motor_axis_2</th>\n",
       "      <th>Array_shape_axis_0</th>\n",
       "      <th>Array_shape_axis_1</th>\n",
       "      <th>Array_shape_axis_2</th>\n",
       "      <th>Voxel_spacing</th>\n",
       "      <th>Number_of_motors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>tomo_049310</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>tomo_098751</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>tomo_136c8d</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>tomo_146de2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>tomo_1dc5f9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>tomo_28f9c1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>tomo_39b15b</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>181</td>\n",
       "      <td>tomo_3b8291</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>193</td>\n",
       "      <td>tomo_40b215</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>219</td>\n",
       "      <td>tomo_4baff0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>924</td>\n",
       "      <td>956</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  row_id      tomo_id  Motor_axis_0  Motor_axis_1  Motor_axis_2  \\\n",
       "0           0      16  tomo_049310          -1.0          -1.0          -1.0   \n",
       "1           1      30  tomo_098751          -1.0          -1.0          -1.0   \n",
       "2           2      54  tomo_136c8d          -1.0          -1.0          -1.0   \n",
       "3           3      59  tomo_146de2          -1.0          -1.0          -1.0   \n",
       "4           4      84  tomo_1dc5f9          -1.0          -1.0          -1.0   \n",
       "5           5     121  tomo_28f9c1          -1.0          -1.0          -1.0   \n",
       "6           6     173  tomo_39b15b          -1.0          -1.0          -1.0   \n",
       "7           7     181  tomo_3b8291          -1.0          -1.0          -1.0   \n",
       "8           8     193  tomo_40b215          -1.0          -1.0          -1.0   \n",
       "9           9     219  tomo_4baff0          -1.0          -1.0          -1.0   \n",
       "\n",
       "   Array_shape_axis_0  Array_shape_axis_1  Array_shape_axis_2  Voxel_spacing  \\\n",
       "0                 500                 924                 956           19.7   \n",
       "1                 500                 924                 956           16.1   \n",
       "2                 500                 924                 956           19.7   \n",
       "3                 500                 924                 956           16.1   \n",
       "4                 500                 924                 956           19.7   \n",
       "5                 500                 924                 956           16.1   \n",
       "6                 500                 924                 956           16.1   \n",
       "7                 500                 924                 956           19.7   \n",
       "8                 500                 924                 956           16.1   \n",
       "9                 500                 924                 956           16.1   \n",
       "\n",
       "   Number_of_motors  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 0  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 0  \n",
       "9                 0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train_csv= '../data/csv_raw/train_labels.csv'\n",
    "path_image= '../data/pictures_process/train_process'\n",
    "df = pd.read_csv(path_train_csv).copy()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79372b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 10 image-label pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/pictures_process/train_process/tomo_2dd6bd',\n",
       " '../data/pictures_process/train_process/tomo_3264bc',\n",
       " '../data/pictures_process/train_process/tomo_54e1a7',\n",
       " '../data/pictures_process/train_process/tomo_974fd4',\n",
       " '../data/pictures_process/train_process/tomo_b8595d',\n",
       " '../data/pictures_process/train_process/tomo_c3619a',\n",
       " '../data/pictures_process/train_process/tomo_d6e3c7',\n",
       " '../data/pictures_process/train_process/tomo_db2a10',\n",
       " '../data/pictures_process/train_process/tomo_e96200',\n",
       " '../data/pictures_process/train_process/tomo_fd41c4']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_image_paths,labels = selection_images_labels(df, num_slices=[300], num_motors=[0,1])\n",
    "filtered_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f09611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds, test_paths, test_labels = batches_stack_images_ram(filtered_image_paths,\n",
    "    labels,\n",
    "    shuffle=True,\n",
    "    batch_size=2,\n",
    "    split=True,\n",
    "    val_fraction=0.2,\n",
    "    test_fraction=0.2,\n",
    "    seed=42,\n",
    "    xy_size=960,\n",
    "    target_depth=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8849f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('../data/pictures_process/train_process/tomo_54e1a7',)('../data/pictures_process/train_process/tomo_974fd4',)\n",
      "<class 'tuple'>\n",
      "('../data/pictures_process/train_process/tomo_3264bc',)\n",
      "<class 'tuple'>\n",
      "\n",
      "<class 'tuple'>\n",
      "('../data/pictures_process/train_process/tomo_fd41c4',)\n",
      "<class 'tuple'>\n",
      "('../data/pictures_process/train_process/tomo_e96200',)\n",
      "<class 'tuple'>\n",
      "('../data/pictures_process/train_process/tomo_b8595d',)\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 16:45:57.732543: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n",
      "    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args)\n",
      "\n",
      "TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "\n",
      "\n",
      "2025-06-06 16:45:57.733243: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n",
      "    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args)\n",
      "\n",
      "TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "\n",
      "\n",
      "2025-06-06 16:45:57.733570: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n",
      "    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args)\n",
      "\n",
      "TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "\n",
      "\n",
      "2025-06-06 16:45:57.733924: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n",
      "    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args)\n",
      "\n",
      "TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "\n",
      "\n",
      "2025-06-06 16:45:57.734602: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n",
      "    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args)\n",
      "\n",
      "TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "\n",
      "\n",
      "2025-06-06 16:45:57.734780: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    return func(device, token, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n",
      "    ret = self._func(*args)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n",
      "    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "\n",
      "  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n",
      "    return f(*args)\n",
      "\n",
      "TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\nTraceback (most recent call last):\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n    return _call_unconverted(f, args, kwargs, options, False)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n    return f(*args)\n\nTypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m volume, label \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVolume batch shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, volume\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel batch shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\nTraceback (most recent call last):\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/var/folders/nj/wg4pl11n6hb1zcpwyf6khsxr0000gn/T/__autograph_generated_file6_h6tttz.py\", line 32, in _load\n    slice_files = ag__.converted_call(ag__.ld(sorted), ([ag__.ld(f) for f in ag__.converted_call(ag__.ld(os).listdir, (ag__.ld(folder),), None, fscope_1) if ag__.converted_call(ag__.ld(f).endswith, ('.jpg',), None, fscope_1)],), None, fscope_1)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 335, in converted_call\n    return _call_unconverted(f, args, kwargs, options, False)\n\n  File \"/Users/benedettaveronesi/.pyenv/versions/3.10.6/envs/flagelleux/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 459, in _call_unconverted\n    return f(*args)\n\nTypeError: listdir: path should be string, bytes, os.PathLike, integer or None, not tuple\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for volume, label in train_ds.take(1):\n",
    "    print(\"Volume batch shape:\", volume.shape)\n",
    "    print(\"Label batch shape:\", label.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flagelleux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
